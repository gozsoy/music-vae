{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import plot_piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# group according to bar length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable declarations\n",
    "\n",
    "TEMPO = 120.  # 1 sec = 2 beats\n",
    "SIXTEENTH_NOTE_BEATS = 0.25  # 1 16th note = 0.25 beats\n",
    "SIXTEENTH_NOTE_LEN = SIXTEENTH_NOTE_BEATS / (TEMPO / 60.)  # 1 16th note = 0.125 sec\n",
    "ONE_BAR_LEN = SIXTEENTH_NOTE_LEN * 16  # 16 16th notes = 1 bar = 2 sec\n",
    "FOUR_BAR_LEN = ONE_BAR_LEN * 4  # 16-bar = 32 sec\n",
    "\n",
    "EVENT_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function definitions\n",
    "\n",
    "def midi_notes2notes_df(notes):\n",
    "\n",
    "    prev_note = notes[0]\n",
    "\n",
    "    processed_notes = []\n",
    "    for temp_note in notes:\n",
    "        pitch = temp_note.pitch\n",
    "        duration = temp_note.end - temp_note.start\n",
    "        step = temp_note.start - prev_note.start\n",
    "        prev_note = temp_note\n",
    "\n",
    "        processed_notes.append({'pitch':pitch,'duration':duration,'step':step})\n",
    "\n",
    "    notes_df = pd.DataFrame.from_dict(processed_notes)\n",
    "\n",
    "    return notes_df\n",
    "\n",
    "\n",
    "def notesdf2midi_notes(notes_df):\n",
    "\n",
    "    recovered_midi_notes = []\n",
    "    current_step = 0.0\n",
    "    for _,row in notes_df.iterrows():\n",
    "        note_duration = row['duration']\n",
    "        current_step = current_step + row['step']\n",
    "        recovered_midi_notes.append(pretty_midi.Note(velocity=100,pitch=int(row['pitch']),start=current_step,end=current_step+note_duration))\n",
    "    \n",
    "    return recovered_midi_notes\n",
    "\n",
    "\n",
    "# reconstruction of recovered notes\n",
    "def pred_df2midi_file(notes_df):\n",
    "    recovered_notes = notesdf2midi_notes(notes_df.iloc[:64])\n",
    "\n",
    "    pm = pretty_midi.Instrument(program=0,is_drum=False)\n",
    "    pm.notes = recovered_notes\n",
    "\n",
    "    recovered_midi_file = pretty_midi.PrettyMIDI(initial_tempo=120.)\n",
    "    recovered_midi_file.instruments = [pm]\n",
    "    recovered_midi_file.time_signature_changes = [pretty_midi.TimeSignature(4,4,0.0)]\n",
    "    recovered_midi_file.write('../data/processed/mini_guitar.mid')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_data = pretty_midi.PrettyMIDI(midi_file='../data/midi_dump/turkish.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_data2tensor(midi_data):\n",
    "    notes = midi_data.instruments[0].notes\n",
    "    notes_df = midi_notes2notes_df(notes)\n",
    "    split_indices = np.arange(start=EVENT_SIZE,stop=len(notes_df),step=EVENT_SIZE)\n",
    "    single_batch_of_events = np.stack(np.split(notes_df.values,split_indices,axis=0)[:-1],axis=0)\n",
    "    return single_batch_of_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gokberk/Desktop/self-projects/music-vae/src/experiments.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/music-vae/src/experiments.ipynb#ch0000084?line=3'>4</a>\u001b[0m complete_batch_of_events \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/music-vae/src/experiments.ipynb#ch0000084?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m midi_file \u001b[39min\u001b[39;00m midi_list:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/music-vae/src/experiments.ipynb#ch0000084?line=6'>7</a>\u001b[0m     midi_data \u001b[39m=\u001b[39m pretty_midi\u001b[39m.\u001b[39mPrettyMIDI(midi_file)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/music-vae/src/experiments.ipynb#ch0000084?line=7'>8</a>\u001b[0m     single_batch_of_events \u001b[39m=\u001b[39m midi_data2tensor(midi_data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/music-vae/src/experiments.ipynb#ch0000084?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m complete_batch_of_events \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/pretty_midi/pretty_midi.py:69\u001b[0m, in \u001b[0;36mPrettyMIDI.__init__\u001b[0;34m(self, midi_file, resolution, initial_tempo)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/pretty_midi/pretty_midi.py?line=66'>67</a>\u001b[0m     tick \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/pretty_midi/pretty_midi.py?line=67'>68</a>\u001b[0m     \u001b[39mfor\u001b[39;00m event \u001b[39min\u001b[39;00m track:\n\u001b[0;32m---> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/pretty_midi/pretty_midi.py?line=68'>69</a>\u001b[0m         event\u001b[39m.\u001b[39mtime \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tick\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/pretty_midi/pretty_midi.py?line=69'>70</a>\u001b[0m         tick \u001b[39m=\u001b[39m event\u001b[39m.\u001b[39mtime\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/pretty_midi/pretty_midi.py?line=71'>72</a>\u001b[0m \u001b[39m# Store the resolution for later use\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "midi_list = glob.glob(\"../data/maestro-v3.0.0/2018/*.midi\")\n",
    "\n",
    "complete_batch_of_events = None\n",
    "\n",
    "for midi_file in midi_list:\n",
    "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
    "    single_batch_of_events = midi_data2tensor(midi_data)\n",
    "    if complete_batch_of_events is None:\n",
    "        complete_batch_of_events = single_batch_of_events\n",
    "    else:\n",
    "        complete_batch_of_events= np.concatenate((complete_batch_of_events,single_batch_of_events),axis=0)\n",
    "\n",
    "print(complete_batch_of_events.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(complete_batch_of_events)\n",
    "train_ds = train_ds.shuffle(1000).batch(6)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_ds in train_ds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE DIMENSION OF X : 128 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional,LSTM,Dense,LSTMCell\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "CONDUCTOR_LEN = 4\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.conductor_dense = Dense(units=512,activation='tanh')\n",
    "        self.conductor_lstm_1 = LSTM(units=512,return_sequences=True)\n",
    "        self.conductor_lstm_2 = LSTM(units=256,return_sequences=True)\n",
    "        self.bottom_lstm_dense = Dense(units=128,activation='tanh')\n",
    "        self.bottom_lstm_1 = LSTM(units=128,return_sequences=True)\n",
    "\n",
    "    def call(self,z,x):\n",
    "        conductor_rnn_h0 = self.conductor_dense(z)\n",
    "        batch_size,_ = conductor_rnn_h0.shape\n",
    "        conductor_input = tf.zeros(shape=(batch_size,CONDUCTOR_LEN,1))\n",
    "        conductor_output = self.conductor_lstm_1(inputs=conductor_input, initial_state=[conductor_rnn_h0, conductor_rnn_h0])\n",
    "        conductor_output = self.conductor_lstm_2(conductor_output)\n",
    "        bottom_input = self.bottom_lstm_dense(conductor_output) \n",
    "\n",
    "        total_seq_len = x.shape[1]\n",
    "        subseq_len = int(total_seq_len/CONDUCTOR_LEN)\n",
    "\n",
    "        for subsec_idx in range(CONDUCTOR_LEN):\n",
    "            bottom_rnn_h0 = bottom_input[:,subsec_idx,:]\n",
    "            subseq_x = x[:,subsec_idx*subseq_len:(subsec_idx+1)*subseq_len,:]\n",
    "            print(bottom_rnn_h0.shape,subseq_x.shape)\n",
    "\n",
    "        return bottom_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# RNN SAMPLING\n",
    "\n",
    "lstm_cell = LSTMCell(units=36)\n",
    "dense_last = Dense(units=3)\n",
    "\n",
    "h0 = tf.random.normal(shape=(temp_ds.shape[0],36))\n",
    "c0 = tf.random.normal(shape=(temp_ds.shape[0],36))\n",
    "\n",
    "h_next,c_next,temp_pred,out = None,None,None,None\n",
    "for j in range(0, temp_ds.shape[1]):\n",
    "    if j == 0:\n",
    "        _, (h_n, c_n) = lstm_cell(inputs=tf.zeros_like(temp_ds[:, j, :]), states=[h0,c0])\n",
    "        h_next,c_next = h_n, c_n\n",
    "        temp_pred = dense_last(h_next)\n",
    "        out = tf.expand_dims(temp_pred,axis=1)\n",
    "    else:\n",
    "        _, (h_n, c_n) = lstm_cell(inputs=temp_pred, states=[h_next,c_next])\n",
    "        h_next,c_next = h_n, c_n\n",
    "        temp_pred = dense_last(h_next)\n",
    "        out = tf.concat([out,tf.expand_dims(temp_pred,axis=1)],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 64, 3])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEACHER FORCING\n",
    "\n",
    "lstm_cell = LSTMCell(units=36)\n",
    "dense_last = Dense(units=3)\n",
    "\n",
    "h0 = tf.random.normal(shape=(temp_ds.shape[0],36))\n",
    "c0 = tf.random.normal(shape=(temp_ds.shape[0],36))\n",
    "\n",
    "h_next,c_next,temp_pred,out = None,None,None,None\n",
    "for j in range(0, temp_ds.shape[1]):\n",
    "    if j == 0:\n",
    "        _, (h_n, c_n) = lstm_cell(inputs=tf.zeros_like(temp_ds[:, j, :]), states=[h0,c0])\n",
    "        h_next,c_next = h_n, c_n\n",
    "        temp_pred = dense_last(h_next)\n",
    "        out = tf.expand_dims(temp_pred,axis=1)\n",
    "    else:\n",
    "        _, (h_n, c_n) = lstm_cell(inputs=temp_ds[:, j, :], states=[h_next,c_next])\n",
    "        h_next,c_next = h_n, c_n\n",
    "        temp_pred = dense_last(h_next)\n",
    "        out = tf.concat([out,tf.expand_dims(temp_pred,axis=1)],axis=1)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 128) (6, 16, 3)\n",
      "(6, 128) (6, 16, 3)\n",
      "(6, 128) (6, 16, 3)\n",
      "(6, 128) (6, 16, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4, 128), dtype=float32, numpy=\n",
       "array([[[-0.07063276,  0.04780326, -0.00672024, ...,  0.0054275 ,\n",
       "          0.01931448, -0.02480353],\n",
       "        [-0.13177484,  0.08146067, -0.01586253, ...,  0.02253362,\n",
       "          0.02968648, -0.02916783],\n",
       "        [-0.17060663,  0.10083238, -0.02863683, ...,  0.04015026,\n",
       "          0.03211647, -0.02892247],\n",
       "        [-0.18978095,  0.10878893, -0.04188544, ...,  0.0552422 ,\n",
       "          0.03172155, -0.02808377]],\n",
       "\n",
       "       [[ 0.00500768, -0.01895826,  0.05834664, ..., -0.00886359,\n",
       "         -0.0007349 , -0.02397226],\n",
       "        [ 0.00654601, -0.02564476,  0.08427896, ..., -0.00467321,\n",
       "         -0.00112684, -0.03542342],\n",
       "        [ 0.00737374, -0.02695352,  0.08764245, ...,  0.00322162,\n",
       "         -0.00491748, -0.03562484],\n",
       "        [ 0.00878097, -0.02479966,  0.07945227, ...,  0.01155077,\n",
       "         -0.0112262 , -0.02956738]],\n",
       "\n",
       "       [[-0.03163254,  0.04645364, -0.06605332, ..., -0.1165111 ,\n",
       "          0.01556935, -0.00789317],\n",
       "        [-0.03304306,  0.07562459, -0.09594174, ..., -0.16460593,\n",
       "          0.03198257,  0.0099323 ],\n",
       "        [-0.02559951,  0.08925494, -0.1078692 , ..., -0.17471781,\n",
       "          0.04924111,  0.03322044],\n",
       "        [-0.01632587,  0.09352257, -0.10889712, ..., -0.16553903,\n",
       "          0.06466064,  0.05599276]],\n",
       "\n",
       "       [[-0.00051075, -0.01376593,  0.02079161, ...,  0.05118201,\n",
       "          0.01980878, -0.04119599],\n",
       "        [-0.00154504, -0.01885812,  0.04000937, ...,  0.06414446,\n",
       "          0.01275059, -0.05620965],\n",
       "        [-0.00523063, -0.01893901,  0.05677104, ...,  0.06204961,\n",
       "         -0.00704059, -0.059359  ],\n",
       "        [-0.00956004, -0.01763067,  0.07125252, ...,  0.05291966,\n",
       "         -0.02911424, -0.05703897]],\n",
       "\n",
       "       [[ 0.03573294, -0.02313938,  0.00761809, ..., -0.00717762,\n",
       "         -0.03359989, -0.00741993],\n",
       "        [ 0.05364167, -0.05294264,  0.01438137, ..., -0.0231789 ,\n",
       "         -0.04710916, -0.01859411],\n",
       "        [ 0.06705908, -0.07747792,  0.02066948, ..., -0.03596792,\n",
       "         -0.04878952, -0.02531309],\n",
       "        [ 0.07597825, -0.09433176,  0.02533196, ..., -0.0438149 ,\n",
       "         -0.04502659, -0.02849562]],\n",
       "\n",
       "       [[ 0.00774353,  0.03210891, -0.0136715 , ..., -0.05731075,\n",
       "         -0.03872672, -0.02386373],\n",
       "        [ 0.01652173,  0.04607626, -0.03544707, ..., -0.06840874,\n",
       "         -0.0562614 , -0.02914951],\n",
       "        [ 0.02497931,  0.05054379, -0.04862154, ..., -0.06216659,\n",
       "         -0.06084736, -0.0266836 ],\n",
       "        [ 0.03126087,  0.04902741, -0.05447168, ..., -0.04951087,\n",
       "         -0.05702892, -0.02078023]]], dtype=float32)>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(4)\n",
    "\n",
    "z = tf.random.normal(shape=(6,256))\n",
    "decoder(z,temp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional,LSTM,Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "def get_encoder(latent_dim):\n",
    "    inputs = tf.keras.Input(shape = (EVENT_SIZE,3))\n",
    "    x = Bidirectional(LSTM(units=1024,return_sequences=True))(inputs)\n",
    "    x = Bidirectional(LSTM(units=1024,return_sequences=False))(x)\n",
    "    mu = Dense(units=latent_dim)(x)\n",
    "    rho = Dense(units=latent_dim)(x)\n",
    "    Encoder = tf.keras.Model(inputs=inputs,outputs=[mu,rho])\n",
    "    \n",
    "    return Encoder\n",
    "\n",
    "def get_decoder(latent_dim):\n",
    "    z = tf.keras.Input(shape = (latent_dim,))\n",
    "    x = tf.keras.layers.Dense(units=120, activation='relu')(z)\n",
    "    x = tf.keras.layers.Dense(units=500, activation='relu')(x)\n",
    "    decoded_img = tf.keras.layers.Dense(units=784)(x)\n",
    "    Decoder = tf.keras.Model(inputs=z,outputs=[decoded_img])\n",
    "    \n",
    "    return Decoder\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self,latent_dim):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_block = get_encoder(latent_dim)\n",
    "        self.decoder_block = get_decoder(latent_dim)\n",
    "\n",
    "    def call(self,img):\n",
    "        z_mu,z_rho = self.encoder_block(img)\n",
    "\n",
    "        epsilon = tf.random.normal(shape=z_mu.shape,mean=0.0,stddev=1.0)\n",
    "        z = z_mu + tf.math.softplus(z_rho) * epsilon\n",
    "\n",
    "        decoded_img = self.decoder_block(z)\n",
    "\n",
    "        return z_mu,z_rho,decoded_img"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a73d1662bd3aab4de55a1a51be85519c6e25d5d617da76d142a49d5ef38ee143"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch_tf_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
